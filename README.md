# Character-Level Text Generation with RNNs

In this project, you'll build your own character-level RNN that learns to generate text in the style of your chosen dataset. By the end, you'll have a unique model and some generated text to show off.

---

## Goal

Train a recurrent neural network (RNN) using Keras and TensorFlow to generate text **character by character** in the style of your selected dataset.

---

## What You’ll Do

1. **Choose a dataset** that interests you (see ideas below).
2. **Preprocess** it for character-level training.
3. **Train** a simple RNN or LSTM model to predict the next character.
4. **Generate text** using your trained model.
5. **Reflect** on the model’s performance and what you learned.

---

## Dataset Ideas

Pick any plain-text corpus that has some style or personality. Some examples:

| Category          | Ideas                                                  |
|------------------|--------------------------------------------------------|
| Literature        | Shakespeare (demo), Emily Dickinson, fairy tales             |
| Lyrics/scripts    | Song lyrics, TV/movie scripts          |
| Code              | Python snippets, SQL queries, regex patterns          |
| Names             | D&D characters, Baby names           |
| Internet          | Reddit posts, tweets, Yelp reviews        |
| Music             | Generate music using abc notation (look up folk rnn) |

**Tip:** Aim for a dataset between 100KB–1MB in size. Plain `.txt` is best.

---

## Deliverables

Your submission should have at least 2 generated samples from your program. You should also answer 

* What dataset did you use, and why?
* What surprised you about the generated text?
* What would you improve next time?

You can turn this is on Canvas

---

Happy generating! 

